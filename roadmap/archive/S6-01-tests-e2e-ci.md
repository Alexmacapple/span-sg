---
bmad_phase: maintenance
bmad_agent: dev
story_type: quality
autonomous: false
validation: human-qa
---

# Story S6-01 : Tests E2E Automatis√©s CI

**Phase** : Semaine 6 - Excellence Technique
**Priorit√©** : Moyenne (P2 - robustesse post-POC)
**Estimation** : 4-6h

---

## Contexte projet

**Apr√®s POC v1.0.0** : Score qualit√© 94/100
- ‚úÖ Coverage scripts production : 89.6%
- ‚úÖ Tests unitaires : 21 tests pytest
- ‚ö†Ô∏è Tests E2E manuels uniquement (`tests/e2e/*.sh`)
- ‚ùå Tests E2E non int√©gr√©s CI ‚Üí r√©gressions d√©tect√©es tardivement

**Scripts E2E existants** :
```
tests/e2e/
‚îú‚îÄ‚îÄ run_all.sh                    # Ex√©cute tous les sc√©narios
‚îú‚îÄ‚îÄ scenario_performance.sh        # Test temps de build
‚îú‚îÄ‚îÄ scenario_frontmatter.sh        # Validation YAML front-matter
‚îú‚îÄ‚îÄ scenario_rollback.sh           # Test int√©grit√© apr√®s rollback
‚îú‚îÄ‚îÄ scenario_erreur_perimetre.sh   # Module avec ‚â†31 points
‚îú‚îÄ‚îÄ scenario_multi_modules.sh      # Calcul scores 6 modules
‚îî‚îÄ‚îÄ README.md                      # Doc tests E2E
```

**Probl√®me** :
- Tests manuels (`./tests/e2e/run_all.sh`) non ex√©cut√©s automatiquement
- CI ne d√©tecte pas r√©gressions comportementales (seulement build/unit)
- Pas de rapport E2E dans Actions

**Objectif S6-01** : Int√©grer tests E2E dans CI avec reporting automatique

---

## Objectif

**Automatiser les tests E2E existants** pour d√©tecter r√©gressions en CI :
- Int√©gration workflow GitHub Actions
- Rapport HTML E2E g√©n√©r√© (artefact upload√©)
- Tests parall√©lis√©s (r√©duction temps CI)
- √âchec CI si tests E2E KO

**Livrables** :
- Job `e2e-tests` dans `.github/workflows/build.yml`
- Rapport HTML E2E (style pytest-html)
- Badge GitHub "E2E Tests Passing"
- Section Tests E2E dans CONTRIBUTING.md

---

## Pr√©requis

- [x] Tests E2E manuels fonctionnels (6 sc√©narios)
- [x] CI existante (build + unit tests + coverage)
- [x] Docker Compose configur√©

---

## √âtapes d'impl√©mentation

### Phase 1 - Pr√©paration Tests E2E (1h)

#### Microt√¢ches

**1.1 Cr√©er script runner E2E pour CI** (30 min)

```bash
# Fichier: tests/e2e/ci_runner.sh
#!/bin/bash
set -e

echo "üß™ Ex√©cution tests E2E CI"

TESTS_DIR="$(dirname "$0")"
REPORT_DIR="$TESTS_DIR/reports"
mkdir -p "$REPORT_DIR"

# Ex√©cuter chaque sc√©nario et capturer r√©sultat
FAILED=0
SCENARIOS=(
    "scenario_performance.sh"
    "scenario_frontmatter.sh"
    "scenario_multi_modules.sh"
    "scenario_erreur_perimetre.sh"
    "scenario_rollback.sh"
)

for scenario in "${SCENARIOS[@]}"; do
    echo ""
    echo "‚ñ∂ Test: $scenario"

    if bash "$TESTS_DIR/$scenario" > "$REPORT_DIR/${scenario%.sh}.log" 2>&1; then
        echo "  ‚úÖ PASS"
    else
        echo "  ‚ùå FAIL"
        FAILED=$((FAILED + 1))
    fi
done

# G√©n√©rer rapport HTML
python3 "$TESTS_DIR/generate_report.py" "$REPORT_DIR"

if [ $FAILED -gt 0 ]; then
    echo ""
    echo "‚ùå $FAILED test(s) E2E √©chou√©(s)"
    exit 1
fi

echo ""
echo "‚úÖ Tous les tests E2E passent"
```

**Checklist** :
- [ ] Script ci_runner.sh cr√©√©
- [ ] Permissions ex√©cution (+x)
- [ ] Logs captur√©s par sc√©nario

**1.2 Cr√©er g√©n√©rateur rapport HTML** (30 min)

```python
# Fichier: tests/e2e/generate_report.py
#!/usr/bin/env python3
"""G√©n√®re rapport HTML tests E2E"""
import sys
from pathlib import Path
from datetime import datetime

def parse_log(log_file):
    """Parse log sc√©nario et extrait r√©sultat"""
    content = log_file.read_text()
    passed = "‚úÖ" in content or "SUCCESS" in content
    return {
        "name": log_file.stem.replace("scenario_", "").replace("_", " ").title(),
        "passed": passed,
        "log": content
    }

def generate_html(report_dir):
    """G√©n√®re rapport HTML depuis logs"""
    logs = sorted(Path(report_dir).glob("*.log"))
    results = [parse_log(log) for log in logs]

    passed = sum(1 for r in results if r["passed"])
    total = len(results)

    html = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Tests E2E SPAN SG</title>
    <style>
        body {{ font-family: monospace; margin: 20px; }}
        .summary {{ background: #f0f0f0; padding: 10px; margin-bottom: 20px; }}
        .pass {{ color: green; }}
        .fail {{ color: red; }}
        .scenario {{ border: 1px solid #ccc; margin: 10px 0; padding: 10px; }}
        pre {{ background: #f5f5f5; padding: 10px; overflow: auto; }}
    </style>
</head>
<body>
    <h1>Tests E2E SPAN SG</h1>
    <div class="summary">
        <strong>R√©sultats</strong> : {passed}/{total} tests passent
        <br><strong>Date</strong> : {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
    </div>
"""

    for result in results:
        status = "‚úÖ PASS" if result["passed"] else "‚ùå FAIL"
        css_class = "pass" if result["passed"] else "fail"
        html += f"""
    <div class="scenario">
        <h2 class="{css_class}">{result["name"]} - {status}</h2>
        <pre>{result["log"]}</pre>
    </div>
"""

    html += """
</body>
</html>
"""

    report_file = Path(report_dir) / "e2e-report.html"
    report_file.write_text(html)
    print(f"Rapport g√©n√©r√© : {report_file}")

if __name__ == "__main__":
    generate_html(sys.argv[1])
```

**Checklist** :
- [ ] Script generate_report.py cr√©√©
- [ ] Parsing logs fonctionnel
- [ ] HTML bien format√©

---

### Phase 2 - Int√©gration CI (2h)

#### Microt√¢ches

**2.1 Ajouter job E2E dans workflow** (1h)

```yaml
# Fichier: .github/workflows/build.yml
# Ajouter apr√®s le job "build"

  e2e-tests:
    name: Tests E2E
    runs-on: ubuntu-latest
    needs: build

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Install system dependencies (qpdf)
        run: |
          sudo apt-get update
          sudo apt-get install -y qpdf

      - name: Run E2E tests
        run: |
          chmod +x tests/e2e/ci_runner.sh
          ./tests/e2e/ci_runner.sh

      - name: Upload E2E report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-report
          path: tests/e2e/reports/e2e-report.html
          retention-days: 30

      - name: Comment PR with E2E results
        if: github.event_name == 'pull_request' && failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: '‚ùå Tests E2E √©chou√©s. Voir rapport dans artifacts.'
            })
```

**Checklist** :
- [ ] Job e2e-tests ajout√© apr√®s build
- [ ] D√©pendances install√©es (Python + qpdf)
- [ ] Rapport upload√© comme artefact
- [ ] Commentaire PR si √©chec

**2.2 Optimiser temps ex√©cution** (30 min)

Strat√©gie : Parall√©lisation avec matrix

```yaml
  e2e-tests:
    name: Tests E2E (${{ matrix.scenario }})
    runs-on: ubuntu-latest
    needs: build
    strategy:
      fail-fast: false
      matrix:
        scenario:
          - performance
          - frontmatter
          - multi_modules
          - erreur_perimetre
          - rollback

    steps:
      # ... setup steps ...

      - name: Run E2E scenario
        run: |
          chmod +x tests/e2e/scenario_${{ matrix.scenario }}.sh
          ./tests/e2e/scenario_${{ matrix.scenario }}.sh
```

**Checklist** :
- [ ] Matrix configur√©e (5 jobs parall√®les)
- [ ] fail-fast: false (tous sc√©narios ex√©cut√©s m√™me si 1 √©choue)
- [ ] Temps CI r√©duit (~3 min ‚Üí ~1 min)

**2.3 Cr√©er badge E2E** (30 min)

```markdown
# Fichier: README.md
# Ajouter apr√®s badge build

[![E2E Tests](https://github.com/Alexmacapple/span-sg-repo/actions/workflows/build.yml/badge.svg?event=push)](https://github.com/Alexmacapple/span-sg-repo/actions/workflows/build.yml)
```

**Checklist** :
- [ ] Badge ajout√© dans README.md
- [ ] Lien vers workflow fonctionnel

---

### Phase 3 - Documentation (1h)

#### Microt√¢ches

**3.1 Documenter tests E2E dans CONTRIBUTING.md** (45 min)

```markdown
# Ajouter section apr√®s "Tests et Coverage"

## Tests End-to-End (E2E)

### Ex√©cuter tests E2E localement

```bash
# Tous les sc√©narios
./tests/e2e/run_all.sh

# Sc√©nario sp√©cifique
./tests/e2e/scenario_performance.sh

# Avec rapport HTML
./tests/e2e/ci_runner.sh
open tests/e2e/reports/e2e-report.html
```

### Sc√©narios E2E disponibles

| Sc√©nario | Description | Temps |
|----------|-------------|-------|
| **performance** | V√©rifie temps build < 30s | ~10s |
| **frontmatter** | Valide YAML front-matter modules | ~5s |
| **multi_modules** | Calcul scores 6 modules | ~8s |
| **erreur_perimetre** | Module ‚â†31 points ‚Üí erreur | ~5s |
| **rollback** | Int√©grit√© apr√®s rollback Git | ~12s |

### Ajouter nouveau test E2E

1. Cr√©er script `tests/e2e/scenario_[nom].sh`
2. Utiliser structure :
   ```bash
   #!/bin/bash
   set -e
   echo "Test: [Description]"
   # ... tests ...
   echo "‚úÖ SUCCESS"
   ```
3. Ajouter dans `ci_runner.sh` (array SCENARIOS)
4. Tester localement : `./tests/e2e/ci_runner.sh`
5. Commit et pusher (CI ex√©cutera automatiquement)

### CI Integration

Tests E2E ex√©cut√©s automatiquement sur :
- ‚úÖ Push vers `draft` ou `main`
- ‚úÖ Pull Requests
- ‚úÖ Parall√©lis√©s (5 jobs simultan√©s)
- ‚úÖ Rapport HTML disponible dans Actions artifacts

En cas d'√©chec :
1. Consulter logs CI (onglet Actions)
2. T√©l√©charger artefact `e2e-report`
3. Ouvrir `e2e-report.html` localement
4. Reproduire sc√©nario √©chou√© en local
```

**Checklist** :
- [ ] Section Tests E2E ajout√©e CONTRIBUTING.md
- [ ] Tableau sc√©narios document√©
- [ ] Guide ajout nouveau test
- [ ] Proc√©dure debugging

**3.2 Mettre √† jour tests/e2e/README.md** (15 min)

```markdown
# Ajouter section CI

## CI Integration

Tests E2E int√©gr√©s dans GitHub Actions (`.github/workflows/build.yml`).

**Ex√©cution automatique** :
- Push vers `draft`/`main`
- Pull Requests
- Parall√©lisation : 5 jobs simultan√©s

**Rapport HTML** :
- G√©n√©r√© automatiquement (`tests/e2e/reports/e2e-report.html`)
- Upload√© comme artefact (r√©tention 30 jours)
- Accessible dans Actions ‚Üí Artifacts

**Commande locale (identique CI)** :
```bash
./tests/e2e/ci_runner.sh
```

**Checklist** :
- [ ] Section CI ajout√©e
- [ ] Lien vers workflow
- [ ] Commande locale document√©e

---

### Phase 4 - Tests & Validation (1-2h)

#### Microt√¢ches

**4.1 Tester ci_runner.sh localement** (30 min)

```bash
# Ex√©cution compl√®te
./tests/e2e/ci_runner.sh

# V√©rifications
ls -lh tests/e2e/reports/e2e-report.html  # Rapport g√©n√©r√©
open tests/e2e/reports/e2e-report.html     # Visuel OK
echo $?                                     # Exit code 0
```

**Checklist** :
- [ ] Tous sc√©narios passent
- [ ] Rapport HTML g√©n√©r√©
- [ ] Logs captur√©s par sc√©nario
- [ ] Exit code 0 si succ√®s

**4.2 Pusher branche feature et v√©rifier CI** (30 min)

```bash
git checkout -b feature/s6-01-e2e-ci
git add tests/e2e/ci_runner.sh tests/e2e/generate_report.py .github/workflows/build.yml
git commit -m "feat(tests): int√®gre tests E2E dans CI (S6-01)

- Ajoute ci_runner.sh pour ex√©cution automatique
- G√©n√®re rapport HTML E2E
- Job GitHub Actions avec parall√©lisation (5 sc√©narios)
- Upload artefact e2e-report
- Badge E2E dans README
- Documentation CONTRIBUTING.md

Closes: roadmap/S6-01-tests-e2e-ci.md"
git push -u origin feature/s6-01-e2e-ci
```

**Checklist CI** :
- [ ] Workflow s'ex√©cute sans erreur
- [ ] Job e2e-tests visible dans Actions
- [ ] Artefact e2e-report upload√©
- [ ] Badge E2E vert dans README

**4.3 Cr√©er PR et valider** (30 min)

```bash
# Cr√©er PR vers draft
gh pr create --title "feat(tests): Tests E2E automatis√©s CI (S6-01)" \
  --body "## Objectif
Int√©gration tests E2E existants dans CI GitHub Actions.

## Changements
- ‚úÖ Script ci_runner.sh (orchestration tests)
- ‚úÖ G√©n√©rateur rapport HTML (generate_report.py)
- ‚úÖ Job GitHub Actions avec parall√©lisation
- ‚úÖ Upload artefact e2e-report (30 jours r√©tention)
- ‚úÖ Badge E2E dans README
- ‚úÖ Documentation CONTRIBUTING.md

## Tests
- [x] ci_runner.sh local : 5/5 sc√©narios passent
- [x] CI ex√©cution : job e2e-tests ‚úÖ
- [x] Rapport HTML g√©n√©r√© et accessible
- [x] Badge E2E fonctionnel

## Impact
- D√©tection r√©gressions comportementales en CI
- Temps CI : +1-2 min (parall√©lis√©)
- Couverture tests : +5 sc√©narios critiques

ü§ñ Generated with [Claude Code](https://claude.com/claude-code)" \
  --base draft
```

**Checklist PR** :
- [ ] PR cr√©√©e vers `draft`
- [ ] CI passe (build + unit + e2e)
- [ ] Rapport e2e-report t√©l√©chargeable
- [ ] Revue Alex/Bertrand

---

## Crit√®res d'acceptation

### Fonctionnels
- [ ] 5 sc√©narios E2E ex√©cut√©s automatiquement en CI
- [ ] Rapport HTML g√©n√©r√© et upload√© (artefact)
- [ ] Badge E2E ajout√© dans README
- [ ] CI √©choue si tests E2E KO

### Techniques
- [ ] Script ci_runner.sh fonctionnel
- [ ] G√©n√©rateur HTML (generate_report.py) fonctionnel
- [ ] Job GitHub Actions configur√©
- [ ] Parall√©lisation (5 jobs simultan√©s)
- [ ] Logs E2E captur√©s par sc√©nario

### Documentation
- [ ] Section Tests E2E dans CONTRIBUTING.md
- [ ] Guide ajout nouveau test E2E
- [ ] tests/e2e/README.md mis √† jour

### Performance
- [ ] Temps CI total : +1-2 min max (parall√©lis√©)
- [ ] Rapport HTML < 500 KB

---

## Risques & Solutions

### Risque 1 : Tests E2E flaky (intermittents)
**Probabilit√©** : Moyenne
**Impact** : Moyen (faux n√©gatifs CI)

**Solution** :
- Ajouter retry automatique (3 tentatives)
- Timeout par sc√©nario (max 60s)
- Logs d√©taill√©s pour debugging

### Risque 2 : Temps CI trop long
**Probabilit√©** : Faible
**Impact** : Moyen (ralentit workflow)

**Solution** :
- Parall√©lisation avec matrix (d√©j√† pr√©vu)
- Cache d√©pendances Python (actions/cache)
- Skip tests E2E sur commits docs-only

### Risque 3 : Rapport HTML trop volumineux
**Probabilit√©** : Faible
**Impact** : Faible (quota artefacts)

**Solution** :
- Limiter logs √† 1000 lignes/sc√©nario
- Compresser rapport (gzip)
- R√©tention 30 jours (pas 90)

---

## M√©triques succ√®s

**Avant S6-01** :
- Tests E2E manuels uniquement
- R√©gressions d√©tect√©es tardivement
- Pas de rapport automatique

**Apr√®s S6-01** :
- 5 sc√©narios E2E automatis√©s
- D√©tection r√©gressions en CI (<5 min)
- Rapport HTML disponible dans Actions
- Coverage tests : Unit (89.6%) + E2E (5 sc√©narios)

**Impact scoring** : 94/100 ‚Üí 96/100 (+2 points Tests)

---

## D√©pendances

**Bloquants** : Aucun (tests E2E existent)

**Facilitateurs** :
- S5-01 (Coverage 89%+) : Tests unitaires robustes
- S2-06 (Tests E2E manuels) : Sc√©narios √©prouv√©s

**Bloque** :
- S6-02 (Notifications CI) : Notifications √©checs E2E

---

## Notes d'impl√©mentation

### Alternative : pytest pour tests E2E
**Option non retenue** : R√©√©crire tests shell en Python/pytest

**Justification** :
- Tests shell existants fonctionnels (6 sc√©narios)
- Temps migration : +4-6h
- B√©n√©fice faible (scripts shell suffisants pour E2E)
- Priorit√© : int√©gration rapide, pas refactoring

### √âvolution future (v2.0)
- Tests E2E cross-platform (macOS, Windows)
- Tests charge (1000+ modules)
- Tests accessibilit√© PDF (pa11y)
- Int√©gration Playwright (tests UI MkDocs)
